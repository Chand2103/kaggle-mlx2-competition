{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97155,"databundleVersionId":11561901,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"4e955948-2e69-4a26-95bc-897b17b6e063","_cell_guid":"ba1fc55f-e87e-41fe-ba1b-2f47f1b0af7a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-13T22:01:40.170648Z","iopub.execute_input":"2025-08-13T22:01:40.170914Z","iopub.status.idle":"2025-08-13T22:01:40.528617Z","shell.execute_reply.started":"2025-08-13T22:01:40.170889Z","shell.execute_reply":"2025-08-13T22:01:40.527701Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"/kaggle/input/mlx-2-0-regression/sample_submission.csv\n/kaggle/input/mlx-2-0-regression/train.csv\n/kaggle/input/mlx-2-0-regression/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Import Required Libraries\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, median_absolute_error, max_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import Ridge\nimport lightgbm as lgb\nimport xgboost as xgb","metadata":{"_uuid":"02cd7dac-08a5-4f23-835d-e8ba99b2949b","_cell_guid":"0cfd876a-5ca0-4dff-b2ed-76a3806ab86f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-13T22:01:40.529908Z","iopub.execute_input":"2025-08-13T22:01:40.530313Z","iopub.status.idle":"2025-08-13T22:01:47.987558Z","shell.execute_reply.started":"2025-08-13T22:01:40.530289Z","shell.execute_reply":"2025-08-13T22:01:47.986693Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load and Initial Data Exploration\ntrain = pd.read_csv('/kaggle/input/mlx-2-0-regression/train.csv')\ntest = pd.read_csv('/kaggle/input/mlx-2-0-regression/test.csv')\n\nprint(f\"Train shape: {train.shape}\")\nprint(f\"Test shape: {test.shape}\")\n\n# Store test IDs and remove from datasets\ntest_ids = test['id'].copy()\ntrain = train.drop(['id'], axis=1)\ntest = test.drop(['id'], axis=1)\n\n# Remove duplicates\ntrain = train.drop_duplicates()\nprint(f\"Train shape after removing duplicates: {train.shape}\")","metadata":{"_uuid":"c51f90d4-48a2-4dd6-ba70-cb25d7d59081","_cell_guid":"fdcd8e9d-d2ef-427c-81e7-84188052a2a1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-13T22:01:47.988444Z","iopub.execute_input":"2025-08-13T22:01:47.988972Z","iopub.status.idle":"2025-08-13T22:01:50.561734Z","shell.execute_reply.started":"2025-08-13T22:01:47.988949Z","shell.execute_reply":"2025-08-13T22:01:50.560788Z"}},"outputs":[{"name":"stdout","text":"Train shape: (61609, 62)\nTest shape: (41074, 61)\nTrain shape after removing duplicates: (61515, 61)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Define Evaluation Functions\ndef calculate_mape(y_true, y_pred):\n    \"\"\"Calculate Mean Absolute Percentage Error\"\"\"\n    # Add small epsilon to avoid division by zero\n    epsilon = 1e-8\n    return np.mean(np.abs((y_true - y_pred) / (y_true + epsilon))) * 100\n\ndef calculate_all_metrics(y_true, y_pred):\n    \"\"\"Calculate all evaluation metrics\"\"\"\n    metrics = {}\n    \n    # RMSE (Root Mean Squared Error)\n    metrics['RMSE'] = np.sqrt(mean_squared_error(y_true, y_pred))\n    \n    # MAE (Mean Absolute Error)\n    metrics['MAE'] = mean_absolute_error(y_true, y_pred)\n    \n    # R² Score\n    metrics['R2'] = r2_score(y_true, y_pred)\n    \n    # Median AE (Median Absolute Error)\n    metrics['Median_AE'] = median_absolute_error(y_true, y_pred)\n    \n    # MAPE (Mean Absolute Percentage Error)\n    metrics['MAPE'] = calculate_mape(y_true, y_pred)\n    \n    # Max Error\n    metrics['Max_Error'] = max_error(y_true, y_pred)\n    \n    return metrics\n\ndef print_metrics(metrics, model_name=\"Model\"):\n    \"\"\"Print all metrics in a formatted way\"\"\"\n    print(f\"\\n{model_name} Performance Metrics:\")\n    print(\"-\" * 40)\n    print(f\"RMSE:       {metrics['RMSE']:.4f}\")\n    print(f\"MAE:        {metrics['MAE']:.4f}\")\n    print(f\"R² Score:   {metrics['R2']:.4f}\")\n    print(f\"Median AE:  {metrics['Median_AE']:.4f}\")\n    print(f\"MAPE:       {metrics['MAPE']:.2f}%\")\n    print(f\"Max Error:  {metrics['Max_Error']:.4f}\")","metadata":{"_uuid":"ac2cbb33-6898-471c-925d-44beb5efb20d","_cell_guid":"fecec39b-ccbe-400d-81e1-16d1ab372af7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-13T22:01:50.562651Z","iopub.execute_input":"2025-08-13T22:01:50.562982Z","iopub.status.idle":"2025-08-13T22:01:50.570625Z","shell.execute_reply.started":"2025-08-13T22:01:50.562955Z","shell.execute_reply":"2025-08-13T22:01:50.569748Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Feature Engineering - Categorical Cleaning\ndef clean_categorical_features(train_df, test_df):\n    \"\"\"Clean and encode categorical features\"\"\"\n    \n    # Categorical columns that need cleaning\n    cat_cols = ['composition_label_0', 'composition_label_1', 'composition_label_2', \n                'creator_collective', 'track_identifier']\n    \n    for col in cat_cols:\n        if col not in train_df.columns:\n            continue\n            \n        # Find common labels between train and test\n        train_labels = set(train_df[col].unique())\n        test_labels = set(test_df[col].unique())\n        common_labels = train_labels.intersection(test_labels)\n        \n        # Replace uncommon labels with 'Other'\n        train_df[col] = train_df[col].apply(lambda x: x if x in common_labels else 'Other')\n        test_df[col] = test_df[col].apply(lambda x: x if x in common_labels else 'Other')\n        \n        # Handle rare categories (frequency <= 5)\n        freq_threshold = 5 if col != 'creator_collective' else 2\n        \n        value_counts = train_df[col].value_counts()\n        rare_labels = value_counts[value_counts <= freq_threshold].index\n        \n        train_df[col] = train_df[col].apply(lambda x: 'Rare' if x in rare_labels else x)\n        test_df[col] = test_df[col].apply(lambda x: 'Rare' if x in rare_labels else x)\n    \n    return train_df, test_df","metadata":{"_uuid":"7c6d366c-2863-4173-bcd1-5738ae99dafb","_cell_guid":"4686c3c0-a267-469b-80c9-45ec84485aca","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-13T22:01:50.572613Z","iopub.execute_input":"2025-08-13T22:01:50.572870Z","iopub.status.idle":"2025-08-13T22:01:50.610829Z","shell.execute_reply.started":"2025-08-13T22:01:50.572850Z","shell.execute_reply":"2025-08-13T22:01:50.609867Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Feature Engineering - Encoding\ndef encode_features(train_df, test_df):\n    \"\"\"Encode categorical features\"\"\"\n    \n    # Frequency encoding for high-cardinality features\n    freq_encode_cols = ['composition_label_0', 'composition_label_1', 'composition_label_2', \n                        'creator_collective', 'track_identifier']\n    \n    for col in freq_encode_cols:\n        if col in train_df.columns:\n            freq = train_df[col].value_counts(normalize=True)\n            train_df[col] = train_df[col].map(freq)\n            test_df[col] = test_df[col].map(freq).fillna(0)\n    \n    # Label encoding for low-cardinality features\n    label_encode_cols = ['season_of_release', 'lunar_phase', 'weekday_of_release']\n    \n    for col in label_encode_cols:\n        if col in train_df.columns:\n            le = LabelEncoder()\n            combined = pd.concat([train_df[col], test_df[col]], axis=0).astype(str)\n            le.fit(combined)\n            train_df[col] = le.transform(train_df[col].astype(str))\n            test_df[col] = le.transform(test_df[col].astype(str))\n    \n    return train_df, test_df","metadata":{"_uuid":"9993c4cc-2fba-4579-b861-b3225baa8d07","_cell_guid":"ebaa9813-2e30-4e50-b494-7f3214985b5e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-13T22:01:50.611712Z","iopub.execute_input":"2025-08-13T22:01:50.612171Z","iopub.status.idle":"2025-08-13T22:01:50.628156Z","shell.execute_reply.started":"2025-08-13T22:01:50.612139Z","shell.execute_reply":"2025-08-13T22:01:50.627186Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Feature Engineering - Create Additional Features\ndef create_features(df):\n    \"\"\"Create additional features\"\"\"\n    \n    # Audio feature aggregations (if available)\n    audio_features = []\n    for prefix in ['duration_ms_', 'rhythmic_cohesion_', 'intensity_index_', \n                   'organic_texture_', 'beat_frequency_']:\n        cols = [col for col in df.columns if col.startswith(prefix)]\n        if cols:\n            audio_features.extend(cols)\n            # Create mean, std, max, min features\n            df[f'{prefix}mean'] = df[cols].mean(axis=1)\n            df[f'{prefix}std'] = df[cols].std(axis=1)\n            df[f'{prefix}max'] = df[cols].max(axis=1)\n            df[f'{prefix}min'] = df[cols].min(axis=1)\n    \n    return df","metadata":{"_uuid":"91a41bd1-8bd3-4e96-b166-f38a23c020ae","_cell_guid":"ee7ad9a8-a0d4-4baf-ade1-803912f73cbe","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-13T22:01:50.629071Z","iopub.execute_input":"2025-08-13T22:01:50.629321Z","iopub.status.idle":"2025-08-13T22:01:50.643811Z","shell.execute_reply.started":"2025-08-13T22:01:50.629302Z","shell.execute_reply":"2025-08-13T22:01:50.642955Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Apply Feature Engineering\nprint(\"Cleaning categorical features...\")\ntrain, test = clean_categorical_features(train, test)\n\nprint(\"Encoding features...\")\ntrain, test = encode_features(train, test)\n\nprint(\"Creating additional features...\")\ntrain = create_features(train)\ntest = create_features(test)","metadata":{"_uuid":"521759d2-2b5e-449d-b12b-75f19fb2962d","_cell_guid":"b6e748f1-be40-489b-b73e-bae95f7b4e40","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-13T22:01:50.644655Z","iopub.execute_input":"2025-08-13T22:01:50.644906Z","iopub.status.idle":"2025-08-13T22:01:52.176348Z","shell.execute_reply.started":"2025-08-13T22:01:50.644887Z","shell.execute_reply":"2025-08-13T22:01:52.175693Z"}},"outputs":[{"name":"stdout","text":"Cleaning categorical features...\nEncoding features...\nCreating additional features...\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Final Data Preprocessing\n# Drop timestamp column (replace with better datetime features if needed)\nif 'publication_timestamp' in train.columns:\n    train = train.drop(['publication_timestamp'], axis=1)\nif 'publication_timestamp' in test.columns:\n    test = test.drop(['publication_timestamp'], axis=1)\n\n# Handle missing values\ntrain = train.fillna(-1)\ntest = test.fillna(-1)\n\n# Prepare features and target\nX = train.drop(['target'], axis=1)\ny = train['target']\n\nprint(f\"Final feature shape: {X.shape}\")","metadata":{"_uuid":"d1c03687-72be-4441-89df-752c895b81ed","_cell_guid":"aa2e9e1a-34fe-4910-8fb7-b4229be6ed73","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-13T22:01:52.177136Z","iopub.execute_input":"2025-08-13T22:01:52.177348Z","iopub.status.idle":"2025-08-13T22:01:52.290041Z","shell.execute_reply.started":"2025-08-13T22:01:52.177332Z","shell.execute_reply":"2025-08-13T22:01:52.289284Z"}},"outputs":[{"name":"stdout","text":"Final feature shape: (61515, 79)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Cross-Validation Function\ndef cv_model(model, X, y, test_data, n_splits=5):\n    \"\"\"Cross-validation with a single model and enhanced metrics\"\"\"\n    \n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n    oof_preds = np.zeros(len(X))\n    test_preds = np.zeros(len(test_data))\n    \n    fold_metrics = []\n    \n    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n        \n        # Fit model\n        if hasattr(model, 'fit'):\n            if 'lgb' in str(type(model)).lower():\n                model.fit(X_train, y_train, \n                         eval_set=[(X_val, y_val)], \n                         callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)])\n            elif 'xgb' in str(type(model)).lower():\n                model.fit(X_train, y_train, \n                         eval_set=[(X_val, y_val)], \n                         verbose=False)\n            else:\n                model.fit(X_train, y_train)\n        \n        # Predict\n        val_pred = model.predict(X_val)\n        test_pred = model.predict(test_data)\n        \n        oof_preds[val_idx] = val_pred\n        test_preds += test_pred / n_splits\n        \n        # Calculate all metrics for this fold\n        fold_metric = calculate_all_metrics(y_val, val_pred)\n        fold_metrics.append(fold_metric)\n        \n        print(f\"Fold {fold+1} - RMSE: {fold_metric['RMSE']:.4f}, MAE: {fold_metric['MAE']:.4f}, R²: {fold_metric['R2']:.4f}\")\n    \n    # Calculate average metrics across folds\n    avg_metrics = {}\n    for metric in fold_metrics[0].keys():\n        avg_metrics[metric] = np.mean([fm[metric] for fm in fold_metrics])\n    \n    print(f\"\\nAverage CV Metrics:\")\n    print(f\"RMSE: {avg_metrics['RMSE']:.4f}\")\n    print(f\"MAE: {avg_metrics['MAE']:.4f}\")\n    print(f\"R²: {avg_metrics['R2']:.4f}\")\n    \n    return oof_preds, test_preds, avg_metrics","metadata":{"_uuid":"7a9c5790-7311-4576-b817-8fa30ec18665","_cell_guid":"3eccaac9-ceb8-453d-919f-43a24368b3ad","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-13T22:01:52.290902Z","iopub.execute_input":"2025-08-13T22:01:52.291658Z","iopub.status.idle":"2025-08-13T22:01:52.302399Z","shell.execute_reply.started":"2025-08-13T22:01:52.291633Z","shell.execute_reply":"2025-08-13T22:01:52.301605Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Initialize Model Storage\nmodels = {}\noof_predictions = {}\ntest_predictions = {}\nmodel_metrics = {}","metadata":{"_uuid":"9c8d15e1-72b2-4af6-8a9b-41b9d98e97d7","_cell_guid":"6fa8a0d7-b0be-462c-b768-356376ba8121","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-13T22:01:52.303261Z","iopub.execute_input":"2025-08-13T22:01:52.303535Z","iopub.status.idle":"2025-08-13T22:01:52.320155Z","shell.execute_reply.started":"2025-08-13T22:01:52.303516Z","shell.execute_reply":"2025-08-13T22:01:52.319447Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Train LightGBM Model\nprint(\"\\n\" + \"=\"*50)\nprint(\"Training LightGBM...\")\nprint(\"=\"*50)\n\nlgb_model = lgb.LGBMRegressor(\n    n_estimators=1000,\n    learning_rate=0.05,\n    max_depth=6,\n    num_leaves=31,\n    feature_fraction=0.8,\n    bagging_fraction=0.8,\n    bagging_freq=5,\n    random_state=42,\n    verbose=-1\n)\n\noof_lgb, test_lgb, metrics_lgb = cv_model(lgb_model, X, y, test)\nmodels['lgb'] = metrics_lgb['RMSE']\noof_predictions['lgb'] = oof_lgb\ntest_predictions['lgb'] = test_lgb\nmodel_metrics['lgb'] = metrics_lgb","metadata":{"_uuid":"5ec03f39-e2f1-40cf-9e00-ea339354ec87","_cell_guid":"fb4f3edd-1043-47ae-8be8-a370e2bfc350","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-13T22:01:52.321030Z","iopub.execute_input":"2025-08-13T22:01:52.321543Z","iopub.status.idle":"2025-08-13T22:03:00.213455Z","shell.execute_reply.started":"2025-08-13T22:01:52.321514Z","shell.execute_reply":"2025-08-13T22:03:00.212609Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nTraining LightGBM...\n==================================================\nTraining until validation scores don't improve for 50 rounds\nDid not meet early stopping. Best iteration is:\n[1000]\tvalid_0's l2: 99.7481\nFold 1 - RMSE: 9.9874, MAE: 6.6409, R²: 0.7872\nTraining until validation scores don't improve for 50 rounds\nDid not meet early stopping. Best iteration is:\n[1000]\tvalid_0's l2: 102.664\nFold 2 - RMSE: 10.1323, MAE: 6.8018, R²: 0.7817\nTraining until validation scores don't improve for 50 rounds\nDid not meet early stopping. Best iteration is:\n[999]\tvalid_0's l2: 95.8367\nFold 3 - RMSE: 9.7896, MAE: 6.5731, R²: 0.7932\nTraining until validation scores don't improve for 50 rounds\nDid not meet early stopping. Best iteration is:\n[1000]\tvalid_0's l2: 99.4317\nFold 4 - RMSE: 9.9715, MAE: 6.6310, R²: 0.7855\nTraining until validation scores don't improve for 50 rounds\nDid not meet early stopping. Best iteration is:\n[1000]\tvalid_0's l2: 99.1716\nFold 5 - RMSE: 9.9585, MAE: 6.6518, R²: 0.7846\n\nAverage CV Metrics:\nRMSE: 9.9679\nMAE: 6.6597\nR²: 0.7864\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Train XGBoost Model\nprint(\"\\n\" + \"=\"*50)\nprint(\"Training XGBoost...\")\nprint(\"=\"*50)\n\nxgb_model = xgb.XGBRegressor(\n    n_estimators=1000,\n    learning_rate=0.05,\n    max_depth=6,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42,\n    verbosity=0\n)\n\noof_xgb, test_xgb, metrics_xgb = cv_model(xgb_model, X, y, test)\nmodels['xgb'] = metrics_xgb['RMSE']\noof_predictions['xgb'] = oof_xgb\ntest_predictions['xgb'] = test_xgb\nmodel_metrics['xgb'] = metrics_xgb","metadata":{"_uuid":"2cef62ce-1873-45be-b18f-ef249545dd0c","_cell_guid":"94df16b3-c008-415e-80a7-a95e178515b8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-13T22:03:00.214400Z","iopub.execute_input":"2025-08-13T22:03:00.214737Z","iopub.status.idle":"2025-08-13T22:05:11.707906Z","shell.execute_reply.started":"2025-08-13T22:03:00.214711Z","shell.execute_reply":"2025-08-13T22:05:11.707090Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nTraining XGBoost...\n==================================================\nFold 1 - RMSE: 9.6869, MAE: 6.2150, R²: 0.7998\nFold 2 - RMSE: 9.7830, MAE: 6.3201, R²: 0.7965\nFold 3 - RMSE: 9.4397, MAE: 6.0566, R²: 0.8077\nFold 4 - RMSE: 9.6631, MAE: 6.2160, R²: 0.7986\nFold 5 - RMSE: 9.6926, MAE: 6.2251, R²: 0.7959\n\nAverage CV Metrics:\nRMSE: 9.6531\nMAE: 6.2066\nR²: 0.7997\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Create Ensemble Model\nprint(\"\\n\" + \"=\"*50)\nprint(\"Creating Ensemble...\")\nprint(\"=\"*50)\n\n# Simple weighted average based on CV scores\nweights = {}\ntotal_inv_score = sum(1/score for score in models.values())\n\nfor model_name, score in models.items():\n    weights[model_name] = (1/score) / total_inv_score\n    print(f\"{model_name} weight: {weights[model_name]:.3f} (CV RMSE: {score:.4f})\")\n\n# Create ensemble predictions\nensemble_oof = np.zeros(len(y))\nensemble_test = np.zeros(len(test))\n\nfor model_name in models.keys():\n    ensemble_oof += weights[model_name] * oof_predictions[model_name]\n    ensemble_test += weights[model_name] * test_predictions[model_name]\n\n# Calculate ensemble metrics\nensemble_metrics = calculate_all_metrics(y, ensemble_oof)","metadata":{"_uuid":"66332756-71a0-442b-a398-912316b8b2ab","_cell_guid":"f8312c73-7830-4007-8f57-c02fa0ab06a3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-13T22:05:11.710391Z","iopub.execute_input":"2025-08-13T22:05:11.710682Z","iopub.status.idle":"2025-08-13T22:05:11.729079Z","shell.execute_reply.started":"2025-08-13T22:05:11.710659Z","shell.execute_reply":"2025-08-13T22:05:11.727756Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nCreating Ensemble...\n==================================================\nlgb weight: 0.492 (CV RMSE: 9.9679)\nxgb weight: 0.508 (CV RMSE: 9.6531)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Display Detailed Results\nprint(\"\\n\" + \"=\"*60)\nprint(\"DETAILED MODEL COMPARISON\")\nprint(\"=\"*60)\n\n# Print individual model metrics\nfor model_name, metrics in model_metrics.items():\n    print_metrics(metrics, f\"{model_name.upper()} Model\")\n\n# Print ensemble metrics\nprint_metrics(ensemble_metrics, \"ENSEMBLE Model\")","metadata":{"_uuid":"15384bb0-3c64-40cb-81b1-6f44e5d79a89","_cell_guid":"ba54dbc4-2235-42ab-9126-1df4e855c96e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-13T22:05:11.730422Z","iopub.execute_input":"2025-08-13T22:05:11.730786Z","iopub.status.idle":"2025-08-13T22:05:11.736514Z","shell.execute_reply.started":"2025-08-13T22:05:11.730764Z","shell.execute_reply":"2025-08-13T22:05:11.735708Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nDETAILED MODEL COMPARISON\n============================================================\n\nLGB Model Performance Metrics:\n----------------------------------------\nRMSE:       9.9679\nMAE:        6.6597\nR² Score:   0.7864\nMedian AE:  3.6366\nMAPE:       52.24%\nMax Error:  48.0398\n\nXGB Model Performance Metrics:\n----------------------------------------\nRMSE:       9.6531\nMAE:        6.2066\nR² Score:   0.7997\nMedian AE:  3.0230\nMAPE:       51.01%\nMax Error:  46.7391\n\nENSEMBLE Model Performance Metrics:\n----------------------------------------\nRMSE:       9.7382\nMAE:        6.3651\nR² Score:   0.7962\nMedian AE:  3.2661\nMAPE:       51.47%\nMax Error:  48.8148\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Display Summary Comparison\nprint(\"\\n\" + \"=\"*60)\nprint(\"SUMMARY COMPARISON\")\nprint(\"=\"*60)\nprint(f\"{'Model':<12} {'RMSE':<8} {'MAE':<8} {'R²':<8} {'MAPE':<8}\")\nprint(\"-\" * 50)\n\nfor model_name, metrics in model_metrics.items():\n    print(f\"{model_name.upper():<12} {metrics['RMSE']:<8.4f} {metrics['MAE']:<8.4f} {metrics['R2']:<8.4f} {metrics['MAPE']:<8.2f}\")\n\nprint(f\"{'ENSEMBLE':<12} {ensemble_metrics['RMSE']:<8.4f} {ensemble_metrics['MAE']:<8.4f} {ensemble_metrics['R2']:<8.4f} {ensemble_metrics['MAPE']:<8.2f}\")","metadata":{"_uuid":"e66ed994-3416-4b9e-86a1-e49bbf8032fc","_cell_guid":"26098ed1-08a0-484b-96ab-b08988d87f60","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-13T22:05:11.737332Z","iopub.execute_input":"2025-08-13T22:05:11.737580Z","iopub.status.idle":"2025-08-13T22:05:11.755200Z","shell.execute_reply.started":"2025-08-13T22:05:11.737561Z","shell.execute_reply":"2025-08-13T22:05:11.754323Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nSUMMARY COMPARISON\n============================================================\nModel        RMSE     MAE      R²       MAPE    \n--------------------------------------------------\nLGB          9.9679   6.6597   0.7864   52.24   \nXGB          9.6531   6.2066   0.7997   51.01   \nENSEMBLE     9.7382   6.3651   0.7962   51.47   \n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Create and Save Submissions\nprint(\"\\nCreating submission files...\")\n\n# Individual model submissions\nsubmission_template = pd.DataFrame({'id': test_ids})\n\nfor model_name, preds in test_predictions.items():\n    submission = submission_template.copy()\n    submission['target'] = np.round(preds).astype(int)  # Round to nearest integer\n    submission.to_csv(f'{model_name}_submission.csv', index=False)\n    print(f\"Saved {model_name}_submission.csv\")\n\n# Ensemble submission\nsubmission = submission_template.copy()\nsubmission['target'] = np.round(ensemble_test).astype(int)  # Round to nearest integer\nsubmission.to_csv('ensemble_submission.csv', index=False)\nprint(\"Saved ensemble_submission.csv\")","metadata":{"_uuid":"617b173f-30ab-4f1e-84c4-bcda106c4637","_cell_guid":"edbf3d78-5dcb-4ee2-adcc-04c9ae4cecf5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-13T22:05:11.756086Z","iopub.execute_input":"2025-08-13T22:05:11.756522Z","iopub.status.idle":"2025-08-13T22:05:11.871787Z","shell.execute_reply.started":"2025-08-13T22:05:11.756493Z","shell.execute_reply":"2025-08-13T22:05:11.870905Z"}},"outputs":[{"name":"stdout","text":"\nCreating submission files...\nSaved lgb_submission.csv\nSaved xgb_submission.csv\nSaved ensemble_submission.csv\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Final Summary\nprint(f\"\\nBest single model: {min(models.keys(), key=lambda x: models[x])} (RMSE: {min(models.values()):.4f})\")\nprint(f\"Ensemble RMSE: {ensemble_metrics['RMSE']:.4f}\")\nprint(f\"Ensemble R²: {ensemble_metrics['R2']:.4f}\")","metadata":{"_uuid":"a5dd5b34-e0cc-43a8-b00f-f109cdbdac04","_cell_guid":"d4630733-fbab-44fd-b38b-bee50f415356","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-13T22:05:11.872638Z","iopub.execute_input":"2025-08-13T22:05:11.872868Z","iopub.status.idle":"2025-08-13T22:05:11.878214Z","shell.execute_reply.started":"2025-08-13T22:05:11.872849Z","shell.execute_reply":"2025-08-13T22:05:11.877519Z"}},"outputs":[{"name":"stdout","text":"\nBest single model: xgb (RMSE: 9.6531)\nEnsemble RMSE: 9.7382\nEnsemble R²: 0.7962\n","output_type":"stream"}],"execution_count":18}]}